{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "\n",
    "## Noelia's ML_OPS Project!  ðŸ‘»ðŸ‘»\n",
    "\n",
    "###  Notebook: users review file data cleaning / data transformation\n",
    "\n",
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "\n",
    "### Import zone\n",
    "\n",
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "### Load data \n",
    "\n",
    "There is not missing data\n",
    "\n",
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rows 1500000  n_cols = 4\n",
      "userId       0\n",
      "rating       0\n",
      "timestamp    0\n",
      "movieId      0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "n_rows 1500000  n_cols = 4\n",
      "userId       0\n",
      "rating       0\n",
      "timestamp    0\n",
      "movieId      0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "n_rows 1500000  n_cols = 4\n",
      "userId       0\n",
      "rating       0\n",
      "timestamp    0\n",
      "movieId      0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "n_rows 1500000  n_cols = 4\n",
      "userId       0\n",
      "rating       0\n",
      "timestamp    0\n",
      "movieId      0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "n_rows 1500000  n_cols = 4\n",
      "userId       0\n",
      "rating       0\n",
      "timestamp    0\n",
      "movieId      0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "n_rows 1500000  n_cols = 4\n",
      "userId       0\n",
      "rating       0\n",
      "timestamp    0\n",
      "movieId      0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "n_rows 524289  n_cols = 4\n",
      "userId       0\n",
      "rating       0\n",
      "timestamp    0\n",
      "movieId      0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "n_rows 1500000  n_cols = 4\n",
      "userId       0\n",
      "rating       0\n",
      "timestamp    0\n",
      "movieId      0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataframes = []\n",
    "\n",
    "sep = \"----------------------------------------------------------------------\"\n",
    "for i in range(1,9):\n",
    "    df = pd.read_csv(f'../data/ratings/{i}.csv')\n",
    "    dataframes.append(df)\n",
    "    n_rows, n_cols = df.shape\n",
    "    print(f\"n_rows {n_rows}  n_cols = {n_cols}\")\n",
    "    print(df.isna().sum())\n",
    "    print(sep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "### Make a huge dataframe and save to csv\n",
    "\n",
    "We cannot track this file in Git, because is too large. We must add this file to .gitignore\n",
    "\n",
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11024289, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mega_df = pd.concat([*dataframes])\n",
    "mega_df = mega_df.reset_index(drop=True)\n",
    "mega_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11024289 entries, 0 to 11024288\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   userId     int64  \n",
      " 1   rating     float64\n",
      " 2   timestamp  int64  \n",
      " 3   movieId    object \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 336.4+ MB\n"
     ]
    }
   ],
   "source": [
    "mega_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "### Drop timestamp column (to save space)\n",
    "\n",
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df.drop(columns=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "### Rename rating column to score to match up with nomenclature used in the platforms datasets.\n",
    "\n",
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df = mega_df.rename(columns={'rating':'score'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "### Save to file /data/clean/all_ratings.csv\n",
    "\n",
    "![divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Individual\n",
    "\n",
    "root_path = '../data/clean/'\n",
    "isExist = os.path.exists(root_path)\n",
    "if not isExist:\n",
    "    # Create a new directory because it does not exist\n",
    "    os.makedirs(root_path)\n",
    "\n",
    "mega_df.to_csv(root_path+\"all_ratings.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91feae2c62c7f7dd8c694bfef93388a2801ca0d10da16ba22787f425e87199c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
